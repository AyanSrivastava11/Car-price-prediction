{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting used car prices\n",
    "\n",
    "In this notebook, I'll work with the [Kaggle](https://www.kaggle.com/avikasliwal/used-cars-price-prediction) dataset about used cars and their prices. The notebook first includes exploration of the dataset followed by prediction of prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries\n",
    "\n",
    "I'll import `datetime` to handle year, `numpy` to work with arrays and `pandas` to read in the dataset files, `matplotlib` & `seaborn` for plotting and `sklearn` for various machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.4' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/ayans/AppData/Local/Programs/Python/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read dataset\n",
    "\n",
    "I'll read the dataset and get information about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"data/dataset.csv\")\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first split the dataset into train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset.iloc[:, :-1], \n",
    "                                                    dataset.iloc[:, -1], \n",
    "                                                    test_size = 0.3, \n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "Let's explore the various columns and draw information about how useful each column is. I'll also modify the test data based on training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index\n",
    "\n",
    "The first column is the index for each data point and hence we can simply remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.iloc[:, 1:]\n",
    "X_test = X_test.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name\n",
    "\n",
    "Let's explore the various cars in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"Name\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it appears, there are several cars in the dataset, some of them with a count higher than 1.\n",
    "Sometimes the resale value of a car also depends on manufacturer of car and hence, I'll extract the manufacturer from this column and add it to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_train = X_train[\"Name\"].str.split(\" \", expand = True)\n",
    "make_test = X_test[\"Name\"].str.split(\" \", expand = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"Manufacturer\"] = make_train[0]\n",
    "X_test[\"Manufacturer\"] = make_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also confirm that there are no null values and identify all unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 8))\n",
    "plot = sns.countplot(x = 'Manufacturer', data = X_train)\n",
    "plt.xticks(rotation = 90)\n",
    "for p in plot.patches:\n",
    "    plot.annotate(p.get_height(), \n",
    "                        (p.get_x() + p.get_width() / 2.0, \n",
    "                         p.get_height()), \n",
    "                        ha = 'center', \n",
    "                        va = 'center', \n",
    "                        xytext = (0, 5),\n",
    "                        textcoords = 'offset points')\n",
    "\n",
    "plt.title(\"Count of cars based on manufacturers\")\n",
    "plt.xlabel(\"Manufacturer\")\n",
    "plt.ylabel(\"Count of cars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximum cars in the dataset are by the manufacturer **Maruti** and there are no null values.\n",
    "\n",
    "I'll also drop the `Name` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(\"Name\", axis = 1, inplace = True)\n",
    "X_test.drop(\"Name\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location\n",
    "\n",
    "Location should not be a determinant for the price of a car and I'll safely remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(\"Location\", axis = 1, inplace = True)\n",
    "X_test.drop(\"Location\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Year\n",
    "\n",
    "Year has no significance on its own unless we try to extract how old a car is from this and see how its resale price may get affected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_time = datetime.datetime.now()\n",
    "X_train['Year'] = X_train['Year'].apply(lambda x : curr_time.year - x)\n",
    "X_test['Year'] = X_test['Year'].apply(lambda x : curr_time.year - x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuel_Type, Transmission,  and Owner_Type\n",
    "\n",
    "All these columns are categorical columns which should be converted to dummy variables before being used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kilometers_Driven\n",
    "\n",
    "`Kilometers_Driven` is a numerical column with a certain range of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"Kilometers_Driven\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data range is really varied and the high values might affect prediction, thus, it is really important that scaling be applied to this column for sure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mileage\n",
    "\n",
    "This column defines the mileage of the car. We need to extract the numerical value out of each string and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mileage_train = X_train[\"Mileage\"].str.split(\" \", expand = True)\n",
    "mileage_test = X_test[\"Mileage\"].str.split(\" \", expand = True)\n",
    "\n",
    "X_train[\"Mileage\"] = pd.to_numeric(mileage_train[0], errors = 'coerce')\n",
    "X_test[\"Mileage\"] = pd.to_numeric(mileage_test[0], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(X_train[\"Mileage\"].isnull()))\n",
    "print(sum(X_test[\"Mileage\"].isnull()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one missing value in each. I'll replace the missing value with the mean value of the column based on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"Mileage\"].fillna(X_train[\"Mileage\"].astype(\"float64\").mean(), inplace = True)\n",
    "X_test[\"Mileage\"].fillna(X_train[\"Mileage\"].astype(\"float64\").mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engine, Power and Seats\n",
    "\n",
    "The `Engine` values are defined in CC so I need to remove `CC` from the data. Similarly, `Power` has bhp, so I'll remove `bhp` from it. Also, as there are missing values in `Engine`, `Power` and `Seats`, I'll again replace them with the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_train = X_train[\"Engine\"].str.split(\" \", expand = True)\n",
    "cc_test = X_test[\"Engine\"].str.split(\" \", expand = True)\n",
    "X_train[\"Engine\"] = pd.to_numeric(cc_train[0], errors = 'coerce')\n",
    "X_test[\"Engine\"] = pd.to_numeric(cc_test[0], errors = 'coerce')\n",
    "\n",
    "bhp_train = X_train[\"Power\"].str.split(\" \", expand = True)\n",
    "bhp_test = X_test[\"Power\"].str.split(\" \", expand = True)\n",
    "X_train[\"Power\"] = pd.to_numeric(bhp_train[0], errors = 'coerce')\n",
    "X_test[\"Power\"] = pd.to_numeric(bhp_test[0], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"Engine\"].fillna(X_train[\"Engine\"].astype(\"float64\").mean(), inplace = True)\n",
    "X_test[\"Engine\"].fillna(X_train[\"Engine\"].astype(\"float64\").mean(), inplace = True)\n",
    "\n",
    "X_train[\"Power\"].fillna(X_train[\"Power\"].astype(\"float64\").mean(), inplace = True)\n",
    "X_test[\"Power\"].fillna(X_train[\"Power\"].astype(\"float64\").mean(), inplace = True)\n",
    "\n",
    "X_train[\"Seats\"].fillna(X_train[\"Seats\"].astype(\"float64\").mean(), inplace = True)\n",
    "X_test[\"Seats\"].fillna(X_train[\"Seats\"].astype(\"float64\").mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Price\n",
    "\n",
    "As most of the values are missing, I'll drop this column altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop([\"New_Price\"], axis = 1, inplace = True)\n",
    "X_test.drop([\"New_Price\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "Now that we have worked with the training data, let's create dummy columns for categorical columns before we begin training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(X_train,\n",
    "                         columns = [\"Manufacturer\", \"Fuel_Type\", \"Transmission\", \"Owner_Type\"],\n",
    "                         drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.get_dummies(X_test,\n",
    "                         columns = [\"Manufacturer\", \"Fuel_Type\", \"Transmission\", \"Owner_Type\"],\n",
    "                         drop_first = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might be possible that the dummy column creation would be different in test and train data, thus, I'd fill in all missing columns with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_cols = set(X_train.columns) - set(X_test.columns)\n",
    "for col in missing_cols:\n",
    "    X_test[col] = 0\n",
    "X_test = X_test[X_train.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, as the last step of data processing, I'll scale the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardScaler = StandardScaler()\n",
    "standardScaler.fit(X_train)\n",
    "X_train = standardScaler.transform(X_train)\n",
    "X_test = standardScaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and predicting\n",
    "\n",
    "I'll create a **Linear Regression** model and a **Random Forest** model to train on the data and use it for future predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearRegression = LinearRegression()\n",
    "linearRegression.fit(X_train, y_train)\n",
    "y_pred = linearRegression.predict(X_test)\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators = 100)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Random Forest** model performed the best with a R2 score of **0.88**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
